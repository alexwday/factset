# Stage 0 Configuration
# Essential settings for historical transcript sync

# SSL Certificate Configuration
ssl_cert_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Inputs/Certificate/rbc-ca-bundle.cer"

# NAS Configuration (loaded from environment)
# nas_share_name comes from NAS_SHARE_NAME environment variable

# API Settings
api_settings:
  # Core API parameters
  industry_categories:
    - "IN:BANKS"
    - "IN:FNLSVC"
    - "IN:INS"
    - "IN:SECS"
  
  transcript_types:
    - "Corrected"
    - "Raw"
  
  # API request configuration
  sort_order:
    - "-storyDateTime"
  pagination_limit: 1000
  pagination_offset: 0
  
  # Rate limiting and retry settings
  request_delay: 3.0
  max_retries: 8
  retry_delay: 10.0
  use_exponential_backoff: true
  max_backoff_delay: 120.0

# Stage 00 specific settings
stage_00_download_historical:
  description: "Historical download using 3-year rolling window or fixed start year"
  output_data_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Data"
  output_logs_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Logs"
  # Optional: Set a fixed start year instead of using 3-year rolling window
  # Uncomment and set to desired year (e.g., 2020) to download from that year to present
  # start_year: 2020

# Stage 01 specific settings
stage_01_download_daily:
  description: "Daily incremental sync of recent transcripts"
  sync_date_range: 1  # Number of days to look back (0 = today only, 1 = today + yesterday)
  output_data_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Data"
  output_logs_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Logs"

# Stage 02 specific settings
stage_02_database_sync:
  description: "Transcript consolidation and master database management"
  input_data_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Data"
  output_logs_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Logs"
  master_database_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Database/master_database.json"
  refresh_output_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Refresh"

# Stage 03 specific settings
stage_03_extract_content:
  description: "XML content extraction and paragraph-level breakdown"
  input_queue_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Refresh/stage_02_process_queue.json"
  output_logs_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Logs"
  output_data_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Refresh"
  dev_mode: true
  dev_max_files: 2

# Stage 04 specific settings
stage_04_validate_structure:
  description: "Transcript content validation"
  input_data_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Refresh/stage_03_extracted_content.json"
  output_logs_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Logs"
  output_data_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Refresh"
  dev_mode: true
  dev_max_files: 2
  expected_sections:
    - "MANAGEMENT DISCUSSION SECTION"
    - "Q&A"

# Stage 05 specific settings (Sliding Window Q&A Pairing)
stage_05_qa_pairing:
  description: "Sliding window Q&A boundary detection and analyst session pairing"
  input_data_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Refresh/stage_04_validated_content.json"
  output_data_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Refresh"
  output_logs_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Logs"
  dev_mode: true
  dev_max_transcripts: 2
  window_size: 5  # Number of speaker blocks per sliding window
  
  # LLM Configuration (OAuth client credentials come from environment variables)
  llm_config:
    base_url: "https://api.openai.com/v1"
    model: "gpt-4o-mini"
    temperature: 0.1
    max_tokens: 500  # Increased for more complex sliding window prompts
    timeout: 60
    max_retries: 3
    token_endpoint: "https://auth.example.com/oauth/token"  # Replace with actual OAuth endpoint
    cost_per_1k_prompt_tokens: 0.00015
    cost_per_1k_completion_tokens: 0.0006

# Stage 06 specific settings (LLM Financial Classification)
stage_06_llm_classification:
  description: "LLM-based financial content classification"
  input_data_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Refresh/stage_05_qa_paired_content.json"
  output_data_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Refresh"
  output_logs_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Logs"
  dev_mode: true
  dev_max_transcripts: 2
  
  # Processing configuration
  processing_config:
    md_paragraph_window_size: 5          # Paragraphs per MD classification call
    max_speaker_blocks_context: 2        # Prior speaker blocks for context
    prior_block_preview_chars: 750       # Characters to show from prior blocks
  
  # LLM configuration
  llm_config:
    base_url: "https://api.openai.com/v1"
    model: "gpt-4o-2024-08-06"
    temperature: 0.0
    max_tokens: 500
    cost_per_1k_prompt_tokens: 0.0025
    cost_per_1k_completion_tokens: 0.01
    timeout: 30
    max_retries: 3
    token_endpoint: "https://auth.example.com/oauth/token"  # Replace with actual OAuth endpoint
  
  # Financial categories are now in financial_categories.yaml

# Stage 07 specific settings (LLM Content Summarization)
stage_07_llm_summarization:
  description: "LLM-based content summarization"
  input_data_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Refresh/stage_06_classified_content.json"
  output_data_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Refresh"
  output_logs_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Logs"
  dev_mode: true
  dev_max_transcripts: 2
  
  # LLM configuration
  llm_config:
    base_url: "https://api.openai.com/v1"
    model: "gpt-4o-2024-08-06"
    temperature: 0.1
    max_tokens: 1000
    cost_per_1k_prompt_tokens: 0.0025
    cost_per_1k_completion_tokens: 0.01
    timeout: 30
    token_endpoint: "https://auth.example.com/oauth/token"  # Replace with actual OAuth endpoint

# Stage 08 specific settings (Embeddings Generation)
stage_08_embeddings_generation:
  description: "Generate vector embeddings from Stage 7 summarized content"
  input_data_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Refresh/stage_07_summarized_content.json"
  output_data_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Refresh"
  output_logs_path: "Finance Data and Analytics/DSA/Earnings Call Transcripts/Outputs/Logs"
  dev_mode: true
  dev_max_transcripts: 10
  
  # Embedding configuration
  embedding_config:
    model: "text-embedding-3-large"
    dimensions: 3072  # Full dimensions
    chunk_threshold: 1000  # Tokens threshold for chunking
    target_chunk_size: 500  # Target size for chunks
    min_final_chunk: 300  # Minimum size for final chunk
    batch_size: 50  # Number of texts to embed in a single API call
    rate_limit_pause: 100  # Pause after this many embeddings
    token_refresh_interval: 500  # Refresh OAuth token after this many embeddings
  
  # LLM configuration (uses same OAuth as Stage 07)
  llm_config:
    base_url: "https://api.openai.com/v1"
    timeout: 30
    max_retries: 3
    token_endpoint: "https://auth.example.com/oauth/token"  # Same as Stage 07

# References to external configuration files
# The monitored_institutions and financial_categories are now in separate files
# to keep this main config cleaner and more maintainable.
# They are loaded by the individual stages as needed.